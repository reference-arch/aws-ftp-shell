{
  "objects": [
     {
      "myComment": "This object is used to set default configuration for objects in the pipeline",

      "id": "Default",
      "failureAndRerunMode": "CASCADE",
      "resourceRole": "DataPipelineDefaultResourceRole",
      "role": "DataPipelineDefaultRole",
      "pipelineLogUri": "#{myS3LogsPath}",
      "name": "Default",
      "scheduleType": "cron",
      "schedule": {
        "ref": "DefaultSchedule"
      }
    },
    {
      "myComment": "This object is used to specify the time-based trigger for executing Activities and for provisioning Resources of the pipeline. 
      In this case it is used by the 'Default' object so it will cascade down to all other objects in the pipeline if they do not override it. 
      For this example, we are using it to specify that our pipeline will run immediately upon activation. Also, we are using the 'occurrences' 
      option specify that the pipeline should only be run once. You can have multiple schedules defined in a pipeline.",

      "type": "Schedule",
      "id": "DefaultSchedule",
      "occurrences": "1",
      "period": "1 Day",
      "startAt": "FIRST_ACTIVATION_DATE_TIME"
    },
    {
      "myComment": "Pipeline object that represents the S3 bucket node that is used as the input staging directory in this pipeline.",

      "type": "S3DataNode",
      "id": "S3InputLocation",
      "directoryPath": "#{myS3InputLoc}"
    },
    {
      "myComment": "Pipeline object that represents the S3 bucket node that is used as the output staging directory in this pipeline.",

      "type": "S3DataNode",
      "id": "S3OutputLocation",
      "directoryPath": "#{myS3OutputLoc}/#{format(@scheduledStartTime, 'YYYY-MM-dd-HH-mm-ss')}",
    },
    {
      "myComment": "This object is a ShellCommandActivity. It is used to specify the command linux shell command that will be invoked. 
      ${INPUT1_STAGING_DIR} is the identifier used to refer to the input staging directory and ${OUTPUT1_STAGING_DIR} is used to refer
      to the output staging directory.",

      "type": "ShellCommandActivity",
      "id": "ShellCommandActivityObj",
      "stage": "true",
      "input": {
        "ref": "S3InputLocation"
      },
      "output": {
        "ref": "S3OutputLocation"
      },
      "runsOn": {
        "ref": "EC2ResourceObj"
      },
      "command": "sftp -b ${Input_STAGING_DIR}/ftpcommands #{user}@#{host}; wc -l data > ${OUTPUT1_STAGING_DIR}/linecount.txt;"
    },
    {
      "myComment": "This object is used to create an Amazon EC2 Instance that activities in the pipeline can run on.",

      "instanceType": "t1.micro",
      "name": "EC2ResourceObj",
      "id": "EC2ResourceObj",
      "type": "Ec2Resource",
      "terminateAfter": "20 Minutes"
    }
  ],
  "parameters": [
    {
      "myComment": "This Parameter specifies the S3 logging path for the pipeline. 
      It is used by the 'Default' object to set the 'pipelineLogUri' value. Using Parameters helps users 
      avoid hard coding variables in pipeline definitions. Users can instead supply these parameters when calling '
      aws datapipeline put-pipeline-definition' or 'aws datapipeline activate-pipeline-definition'.",

      "id" : "myS3LogsPath",
      "type" : "AWS::S3::ObjectKey",
      "description" : "S3 path for pipeline logs."
    },
    {
      "myComment": "This Parameter specifies the S3 input location for the pipeline.",

      "id": "myS3InputLoc",
      "type": "AWS::S3::ObjectKey"
    },
    {
      "myComment": "This Parameter specifies the S3 output location for the pipeline.",

      "id": "myS3OutputLoc",
      "type": "AWS::S3::ObjectKey"
    },
    {
      "myComment": "This Parameter specifies user for the ftp server",

      "id": "user",
      "type": "String"
    },
    {
      "myComment": "This Parameter specifies the ftp server host",

      "id": "host",
      "type": "String"
    }
  ]
}
